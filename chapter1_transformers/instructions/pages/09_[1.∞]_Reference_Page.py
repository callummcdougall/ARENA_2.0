
import os, sys
from pathlib import Path
chapter = r"chapter1_transformers"
instructions_dir = Path(f"{os.getcwd().split(chapter)[0]}/{chapter}/instructions").resolve()
if str(instructions_dir) not in sys.path: sys.path.append(str(instructions_dir))
os.chdir(instructions_dir)

import streamlit as st
import st_dependencies

st_dependencies.styling()

import platform
is_local = (platform.processor() != "")

st.sidebar.markdown(r"""

## Table of Contents

<ul class="contents">
    <li class='margtop'><a class='contents-el' href='#links'>Links</a></li>
    <li><ul class="contents">
        <li><a class='contents-el' href='#logistics'>Logistics</a></li>
        <li><a class='contents-el' href='#general'>General</a></li>
        <li><a class='contents-el' href='#how-transformers-work'>How Transformers Work</a></li>
        <li><a class='contents-el' href='#transformerlens'>TransformerLens</a></li>
        <li><a class='contents-el' href='#diagrams'>Diagrams</a></li>
    </ul></li>
    <li class='margtop'><a class='contents-el' href='#quick-reference'>Quick Reference</a></li>
    <li><ul class="contents">
        <li><a class='contents-el' href='#weights'>Weights</a></li>
        <li><a class='contents-el' href='#hooks'>Hooks</a></li>
        <li><a class='contents-el' href='#making-your-own-hooked-model'>Making your own hooked model</a></li>
        <li><a class='contents-el' href='#cache'>Cache</a></li>
        <li><a class='contents-el' href='#tokenization'>Tokenization</a></li>
        <li><a class='contents-el' href='#utils'>Utils</a></li>
        <li><a class='contents-el' href='#factoredmatrix'>FactoredMatrix</a></li>
        <li><a class='contents-el' href='#circuitsvis'>Circuitsvis</a></li>
        <li><a class='contents-el' href='#pre-trained-checkpoints'>Pre-Trained Checkpoints</a></li>
        <li><a class='contents-el' href='#misc'>Misc.</a></li>
    </ul></li>
</ul></li>""", unsafe_allow_html=True)

st.markdown(r"""
# [1.âˆž] Reference Page

This page contains links to a bunch of things (blog posts, diagrams, tables) as well as guides and code references, all of which are useful to have at hand when doing this chapter.

*If you have any other suggestions for this page, please add them on Slack!*

## Links

### Logistics

* [Notion page](https://www.notion.so/ARENA-2-0-Virtual-Resources-7934b3cbcfbf4f249acac8842f887a99?pvs=4) for people studying virtually
* [ARENA Slack group invite link](https://join.slack.com/t/arena-la82367/shared_invite/zt-1uvoagohe-JUv9xB7Vr143pdx1UBPrzQ)
* [Open Source Mechanistic Interpretability Slack group invite link](https://join.slack.com/t/opensourcemechanistic/shared_invite/zt-1qosyh8g3-9bF3gamhLNJiqCL_QqLFrA)

### General

* [Google Drive folder](https://drive.google.com/drive/folders/1N5BbZVh5_pZ3sH1lv4krp-2_wJrB-Ahg) containing Colab versions of all these exercises
* Neel Nanda's [Mech Interp Dynalist notes](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J)
* Neel Nanda's [Concrete Steps to Get Started in Transformer Mechanistic Interpretability](https://www.neelnanda.io/mechanistic-interpretability/getting-started)
* Neel Nanda's [An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretability Papers](https://www.neelnanda.io/mechanistic-interpretability/favourite-papers)

### How Transformers Work

* Neel Nanda's Implementing a Transformer Walkthrough: [Part 1/2](https://www.youtube.com/watch?v=bOYE6E8JrtU), [Part 2/2](https://www.youtube.com/watch?v=dsjUDacBw8o)
* Callum McDougall's [An Analogy for Understanding Transformers](https://www.lesswrong.com/posts/euam65XjigaCJQkcN/an-analogy-for-understanding-transformers)
* Callum McDougall's [full transformer excalidraw diagram](https://link.excalidraw.com/l/9KwMnW35Xt8/4kxUsfrPeuS)
* Jay Alammar's [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)

### TransformerLens

* TransformerLens documentation page:
    * [Homepage](https://neelnanda-io.github.io/TransformerLens/index.html)
    * [Table of model properties](https://neelnanda-io.github.io/TransformerLens/model_properties_table.html)

### Diagrams

[Link to excalidraw](https://link.excalidraw.com/l/9KwMnW35Xt8/6PEWgOPSxXH) for the diagram below.

<img src="https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/transformer-full-red.png" width="1200">

## Quick reference

Here's a list of some useful functions and methods in TransformerLens.

### Weights

You can index weights via the full name, e.g. `model.blocks[0].attn.W_Q` returns something of shape `(n_heads, d_head, d_model)`. But you can also use `model.W_Q` which returns all the matrices stacked along the layer dimension, i.e. shape `(n_layers, n_heads, d_head, d_model)`. This works for all other weights:

```python
model.W_Q -> query weights
model.W_K -> key weights
model.W_V -> value weights
model.W_O -> output weights

model.W_in -> MLP input weights
model.W_out -> MLP output weights
```

and exactly the same for biases.

### Hooks

Template for a hook function is:

```python
def hook_fn(activation: Tensor, hook: HookPoint):
    # Modify / store activation
    # optionally return new (changed) value of activation
    ...
```

Useful functions for hooks are:

#### `model.add_hooks`

Takes arguments `hook_name` and `hook_fn`. Adds a hook to the model, which will be called and removed after each forward pass.

Note that `hook_name` can be a boolean function which takes names as arguments, in which case the hook will be added to all activations where the function evaluates to True.

Example: `model.add_hooks(lambda name: name.endswith("z"), hook_fn)` adds hooks to `z` at all layers.

#### `model.run_with_hooks`

Used as follows:

```python
out = model.run_with_hooks(
    inputs,
    fwd_hooks = [(hook_name, hook_fn), ...],
    return_type = "logits" # can also do "loss", "both", or None
)
```

#### `model.run_with_cache`

Used as follows:

```python
out, cache = model.run_with_cache(
    inputs,
    return_type = "logits" # can also do "loss", "both", or None
)
```

An optional argument is `names_filter`, which is a boolean function taking names as arguments (we'll only cache the activations where `names_filter(name)` is True).

### Making your own hooked model

Hooks are implemented as special instances of `nn.Identity` modules, which come some special functionality.

The following code snipped shows how to define a simple hooked model, which will have methods like `run_with_hooks` and `run_with_cache`.

```python
from transformer_lens.hook_points import HookedRootModule, HookPoint


class SquareThenAdd(nn.Module):
    def __init__(self, offset):
        super().__init__()
        self.offset = nn.Parameter(torch.tensor(offset))
        self.hook_square = HookPoint()

    def forward(self, x):
        # The hook_square doesn't change the value, but lets us access it
        square = self.hook_square(x * x)
        return self.offset + square


class TwoLayerModel(HookedRootModule):
    def __init__(self):
        super().__init__()
        self.layer1 = SquareThenAdd(3.0)
        self.layer2 = SquareThenAdd(-4.0)
        self.hook_in = HookPoint()
        self.hook_mid = HookPoint()
        self.hook_out = HookPoint()

        # We need to call the setup function of HookedRootModule to build an
        # internal dictionary of modules and hooks, and to give each hook a name
        super().setup()

    def forward(self, x):
        # We wrap the input and each layer's output in a hook - they leave the
        # value unchanged (unless there's a hook added to explicitly change it),
        # but allow us to access it.
        x_in = self.hook_in(x)
        x_mid = self.hook_mid(self.layer1(x_in))
        x_out = self.hook_out(self.layer2(x_mid))
        return x_out


model = TwoLayerModel()
```

### Cache

The `ActivationCache` class has a few useful methods for performing operations on its activations. These include:

* `cache.apply_ln_to_stack(resid_stack: Tensor)`
    * Apply layernorm scaling to a stack of residual stream values.
    * We used this to help us go from "final value in residual stream" to "projection of logits in logit difference directions", without getting the code too messy!
* `cache.accumulated_resid(layer)`
    * Returns the accumulated residual stream up to layer `layer` (or up to the final value of residual stream if layer is None), i.e. a stack of previous residual streams up to that layer's input.
    * Useful when studying the **logit lens**.
    * First dimension of output is `(0_pre, 0_mid, 1_pre, 1_mid, ..., final_post)`.
* `cache.decompose_resid(layer)`.
    * Decomposes the residual stream input to layer `layer` into a stack of the output of previous layers. The sum of these is the input to layer `layer`.
    * First dimension of output is `(embed, pos_embed, 0_attn_out, 0_mlp_out, ...)`.
* `cache.stack_head_results(layer)`
    * Returns a stack of all head results (i.e. residual stream contribution) up to layer `layer`
    * (i.e. like `decompose_resid` except it splits each attention layer by head rather than splitting each layer by attention/MLP)
    * First dimension of output is `layer * head` (we needed to rearrange to `(layer, head)` to plot it).

### Tokenization

Here are some useful functions for tokenization:

* `model.to_str_tokens` maps strings -> list of strings
* `model.to_tokens` maps strings -> tokens (as tensor)
* `model.to_single_tokens` maps a string for a single token -> that token id (as an int)
* `model.to_string` maps an int token id -> string
* `model.get_token_position(token, string)` returns the (first) position of the token in the string

**Gotcha** - remember the `prepend_bos` argument in all of these! When this is true, we prepend the BOS token to the start of the string, and the token positions are shifted by 1.

### Utils

`utils.test_prompt(prompt, answer, model)`

* Tests the model on a prompt, and prints useful output. 
* Useful for exploratory analysis.
* Example: `utils.test_prompt("One plus one equals", " two", gpt2_small)`

`utils.to_numpy`

* Converts a (possibly cuda, attached-to-computational-graph) tensor to a numpy array.
* Don't have to mess around with clone, detach, cpu and numpy methods.

`utils.get_act_name`

* Works the same way as indexing into the cache (actually, this is what gets called under the hood when we index into the cache).
* Returns full name of activation.
* Example: `utils.get_act_name(q, 0)` (second argument is layer index).
* Important - unlike the cache, you can't use negative layer indices.

### Circuitsvis

#### Attention

Circuitsvis is a great way to visualise attention patterns. You can use it as shown in the code below. On the left is an example of `attention_patterns`, on the right is `attention_heads`.

```python
import circuitsvis as cv

cv.attention.attention_patterns(
    tokens, # list of strings
    attention, # tensor of shape (n_heads, seq_len, seq_len),
    attention_head_names
)

cv.attention.attention_heads(
    attention, # tensor of shape (n_heads, seq_len, seq_len),
    tokens, # list of strings
    attention_head_names
)
```""", unsafe_allow_html=True)

cols = st.columns(2)

with cols[0]:
    with open("media/attention_patterns.html") as f:
        st.components.v1.html(f.read(), height=800)
with cols[1]:
    with open("media/attention_heads.html") as f:
        st.components.v1.html(f.read(), height=800)

st.markdown(r"""

A few notes:
* Attention heads and attention patterns have similar syntax, but present information in different ways. Which one you use depends on your use case, and personal preference.
* The version of circuitsvis I'm having people use is a fork of the main library (because the main library doesn't offer the `attention_head_names` argument for the `attention_patterns`) function. I've kept the same order of the first 2 (non-optional) arguments so as not to break compatibility, which for some arcane reason isn't the same for both functions! It's probably safer to use them as keyword arguments so they don't get mixed up.
* Make sure to check that tokens have the right length, and attention has the right shape, because there aren't error messages for this.
* These functions can be called in a cell, but they also return an html object which you can display using `IPython.display.display(html_object)`.
* Sometimes the visualisations can behave weirdly (in particular, the `attention_patterns` visualisation can shrink infinitely after being displayed). A hacky way around this is to save and open the plot in your browser:

```python
import webbrowser

html_obj = cv.attention.attention_patterns(...)

with open("temp.html", "w") as f:
    f.write(str(html_obj))

webbrowser.open("temp.html")
```

If you're in a remote machine then the latter method won't work, but you can right click -> download the html file and open it locally.

#### Neuron Activations

A lesser-known fact is that circuitsvis can also help you visualise neuron activations. Below is some example code (we don't show all neurons, so the page doesn't slow down).

```python
cv.activations.text_neuron_activations(
    tokens, # list of strings
    activations, # list of tensors of shape (seq_pos, layers, neurons)
)
```
""", unsafe_allow_html=True)

with open("media/neurons_1.html") as f:
    st.components.v1.html(f.read(), height=150)

st.markdown(r"""

The next function shows which words each of the neurons activates most / least on (note that it requires some weird indexing to work correctly). Again, we've not shown all neurons.

```python
cv.topk_tokens.topk_tokens(
    tokens, # list of strings, each of length `seq_pos`
    activations, # corresponding list of tensors, each of shape (layers, seq_pos, neurons)
    max_k=4, # how many top/bottom activating tokens to show
)
```

""", unsafe_allow_html=True)

with open("media/neurons_2.html") as f:
    st.components.v1.html(f.read(), height=400)

st.markdown(r"""
### FactoredMatrix

In transformer interpretability, we often need to analyse low rank factorized matrices - a matrix $M = AB$, where M is `[large, large]`, but A is `[large, small]` and B is `[small, large]`. This is a common structure in transformers, and the `FactoredMatrix` class is a convenient way to work with these. It implements efficient algorithms for various operations on these, acting as a drop-in replacement for the actual matrix product. 

We define a factored matrix as follows:

```python
AB_factored = FactoredMatrix(A, B)
```

Some supported methods are:

```python
AB.eigenvalues # returns eigenvalues
AB.U, AB.S, AB.Vh # returns SVD
AB.norm() # returns Frobenius norm
AB.A, AB.B # returns left and right matrices used in product
```

### Pre-Trained Checkpoints

All of TransformerLens' interpretability-friendly models have available checkpoints, including the toy models, SoLU models, and stanford-gpt models.

The checkpoint structure and labels is somewhat messy and ad-hoc, so you're recommended to use the `checkpoint_index` syntax (where you can just count from 0 to the number of checkpoints) rather than `checkpoint_value` syntax (where you need to know the checkpoint schedule, and whether it was labelled with the number of tokens or steps). The helper function `get_checkpoint_labels` tells you the checkpoint schedule for a given model - ie what point was each checkpoint taken at, and what type of label was used.

```python
from transformer_lens.loading_from_pretrained import get_checkpoint_labels
from plotly_utils import line

for model_name in ["attn-only-2l", "solu-12l", "stanford-gpt2-small-a"]:
    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)
    line(checkpoint_labels, labels={"x": "Checkpoint Index", "y": f"Checkpoint Value ({checkpoint_label_type})"}, title=f"Checkpoint Values for {model_name} (Log scale)", log_y=True, markers=True)
for model_name in ["solu-1l-pile", "solu-6l-pile"]:
    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)
    line(checkpoint_labels, labels={"x": "Checkpoint Index", "y": f"Checkpoint Value ({checkpoint_label_type})"}, title=f"Checkpoint Values for {model_name} (Linear scale)", log_y=False, markers=True)
```

### Misc. 

#### Visualisation

Plotly is great - you can find plotly utils functions in these directories (along with many examples of them being used). The `RdBu` colorscheme is your friend!

#### Memory management

Call `torch.enable_grad(False)` to disable gradient tracking, if you don't need it (which you won't most of the time). This saves a lot of memory!

Call `torch.cuda.empty_cache()` to clear memory, if you find yourself needing to.

#### Notebooks vs Python files vs Colabs

It's important to konw what tools to use in different situations. All have advantages and disadvantages.

**Google Colab** provides minimal setup cost, cheap GPU support, and is a good place to share results with others and get feedback. But it also doesn't have some of the same useful tools as VSCode (e.g. Copilot, better editing and navigation features, other extensions, etc).

**VSCode-based ipynb notebooks** are good ways to display results, and are useful for exploratory analysis. Most people find them a more pleasant experience to code in than Colab. However, they do have a larger setup cost, and notebooks can also encourage bad practices (e.g. lack of structure, cluttered code, etc).

**VSCode-based Python files** can be given notebook-like functionality by cell-separation comments `# %%`. You can also write functions in a Python file and import them from other python files and notebooks, which is extremely valuable. But unlike notebooks, then can't display results inline.

Your workflow might use all three of these, e.g. working in VSCode using a combination of notebooks for exploratory analysis and Python files for writing functions that you'll import into your notebooks, then finally converting your notebooks to Colabs to publish your results.

""", unsafe_allow_html=True)